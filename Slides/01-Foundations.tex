\documentclass{beamer}

\input{preamble.tex}
\usepackage{breqn} % Breaks lines

\usepackage{amsmath}
\usepackage{mathtools}

\usepackage{pdfpages} % \includepdf

\usepackage{listings} % R code
\usepackage{verbatim} % verbatim

% Video stuff
\usepackage{media9}

% packages for bibs and cites
\usepackage{natbib}
\usepackage{har2nat}
\newcommand{\possessivecite}[1]{\citeauthor{#1}'s \citeyearpar{#1}}
\usepackage{breakcites}
\usepackage{alltt}

% tikz
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{calc, positioning, decorations.pathreplacing, arrows.meta, intersections}
\pgfdeclarelayer{bg}
\pgfdeclarelayer{back}
\pgfdeclarelayer{fg}
\pgfsetlayers{bg,main,fg,back}
\usetikzlibrary{shapes,arrows}

% Setup math operators
\DeclareMathOperator{\E}{E} \DeclareMathOperator{\tr}{tr} \DeclareMathOperator{\se}{se} \DeclareMathOperator{\I}{I} \DeclareMathOperator{\sign}{sign} \DeclareMathOperator{\supp}{supp} \DeclareMathOperator{\plim}{plim}
\DeclareMathOperator*{\dlim}{\mathnormal{d}\mkern2mu-lim}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
   \def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand*\colvec[1]{\begin{pmatrix}#1\end{pmatrix}}

\newcommand{\myurlshort}[2]{\href{#1}{\textcolor{gray}{\textsf{#2}}}}


\begin{document}

\imageframe{./lecture_includes/mixtape_ci_cover.png}


% ---- Content ----



\section{What is Mixtape Sessions?}

\begin{frame}{Welcome!}

  \begin{itemize}
	\item I'm Scott Cunningham, Ben H. Williams professor of economics at Baylor University, author of \underline{Causal Inference: the Mixtape}
	\item I enjoy learning about economics, econometrics and particularly causal inference and run workshops on causal inference in order to help people make the material more accessible
	\item I work on a variety of eclectic topics -- sex work, methamphetamine drug policy, abortion policy, and more recently, detecting and treating self harm in prisons and jails
	\item Causal inference is an old field but which has increasingly drawn people to it (Nobel Prize two years ago maybe helped) 
  \end{itemize}

\end{frame}




\begin{frame}{Expectations}

  \begin{itemize}
    \item This workshop will cover potential outcomes, randomization, unconfoundedness, instrumental variables and regression discontinuity design
    	\begin{itemize}
	\item Causal Inference 2 will cover diff-in-diff
	\item Causal Inference 3 will cover synthetic control
	\end{itemize}
    \item My teaching style is to try and not leave any one behind so I emphasize a lot of basics, applications, simple things repeatedly and then extend it in more advanced material
  \end{itemize}

\end{frame}





\begin{frame}{Class goals}

  \begin{enumerate}
    \item \textbf{Confidence}: You will feel like you have a good understanding of causal inference so that by the end it doesn't feel all that mysterious or intimidating
    \item \textbf{Comprehension}: You will have learned a lot both conceptually and in the specifics, particularly with regards to issues around identification and estimation
    \item \textbf{Competency}: You will have more knowledge of programming syntax in Stata and R (and python!) so that later you can apply this in your own work
  \end{enumerate}

\end{frame}


%\begin{frame}{Causal Inference table of contents}
%  \centering
%  \includegraphics[scale=0.5,height=6.5cm, width=10cm]{./lecture_includes/part1}
%\end{frame}

%\begin{frame}{Causal Inference Part 2}
%  \centering
%  \includegraphics[scale=0.5,height=6.5cm, width=10cm]{./lecture_includes/part2}
%  \url{https://www.mixtapesessions.io/session/ci_II_aug20}
%\end{frame}




\begin{frame}{Github repo}

  \begin{itemize}
    \item We will communicate with one another regularly in the Discord channel and I will always be monitoring it
    \item Encourage you to talk to each other there, help one another, network with one another, coauthor with one another!
    \item I will be distributing things to you, like code and slides, via a github repo at my platform Mixtape Sessions
    \item Each lecture will be recorded and then uploaded to Vimeo, and we will be experimenting with various AI tools as well
  \end{itemize}

\end{frame}


\begin{frame}{What is Causal Inference?}

\begin{itemize}
\item Causality as a subject when studied by philosophers is divided between metaphysics (a theory of what is) and epistemology (what is knowledge)
\item Causal inference will cover both of these -- how will we define causal effects?  What rules will we use to make a deduction that a causal \emph{belief} (inference) is warranted?
\item It's a rich field, like a mighty river, with many rivers and streams that feed into it and I will try my best to point to them along the way
\item But the majority of this comes from when two approaches of a larger body of work that I think created a distinct approach that might help explain why this material is new but not entirely new
\end{itemize}

\end{frame}

\begin{frame}

\begin{center}
\textbf{Three Tributaries of Causal Inference}
\end{center}

\begin{center}
\begin{tikzpicture}[scale=0.7, every node/.style={scale=0.7}]
% Much More Stuff Stream
\node at (-6,6) {\textbf{Much, Much More}};
\draw[->, thick, decorate, decoration={snake, amplitude=0.5mm, segment length=2mm}] (-6,5.5) -- (-6,4);

% Princeton Stream
\node at (0,6) {\textbf{Princeton}};
\draw[->, thick, decorate, decoration={snake, amplitude=0.5mm, segment length=2mm}] (0,5.5) -- (0,4);

% Harvard Stream
\node at (6,6) {\textbf{Harvard}};
\draw[->, thick, decorate, decoration={snake, amplitude=0.5mm, segment length=2mm}] (6,5.5) -- (6,4);

% The Mixtape Box
\draw[dashed, thick, rounded corners] (-1,5) rectangle (7,6.5);
\node[align=center] at (3,6.8) {\textbf{The Mixtape}};

% Causal Inference Box
\node[rectangle, draw, thick, rounded corners, inner sep=10pt, minimum size=1.5cm, fill=red!10] 
    (causal) at (0,2) {\textbf{Causal Inference}};

% Arrows to Causal Inference
\draw[->, thick, decorate, decoration={snake, amplitude=0.5mm, segment length=2mm}] (-6,4) -- (causal.north west);
\draw[->, thick, decorate, decoration={snake, amplitude=0.5mm, segment length=2mm}] (0,4) -- (causal.north);
\draw[->, thick, decorate, decoration={snake, amplitude=0.5mm, segment length=2mm}] (6,4) -- (causal.north east);

\end{tikzpicture}
\end{center}

\end{frame}

\begin{frame}

\begin{center}
\textbf{Two rivers into causal inference}
\end{center}

\begin{center}
\begin{tikzpicture}[scale=0.7, every node/.style={scale=0.7}]
% Orley Ashenfelter Stream
\node at (-5,6) {\textbf{Orley Ashenfelter}};
\draw[->, thick] (-5,5.5) -- (-5,5.2);
\node at (-5,5) {Princeton Industrial Relations Section};
\draw[->, thick] (-5,4.5) -- (-5,4.2);
\node at (-5,4) {Quasi-Experimental Design};
\draw[->, thick] (-5,3.5) -- (-5,3.2);
\node at (-5,3) {\textbf{David Card}};
\draw[->, thick] (-5,2.5) -- (-5,2.2);
\node at (-5,2) {Difference-in-differences};
\draw[->, thick] (-5,1.5) -- (-5,1.2);

% Don Rubin Stream
\node at (5,6) {\textbf{Don Rubin}};
\draw[->, thick] (5,5.5) -- (5,5.2);
\node at (5,5) {Harvard Statistics};
\draw[->, thick] (5,4.5) -- (5,4.2);
\node at (5,4) {Experimental Design};
\draw[->, thick] (5,3.5) -- (5,3.2);
\node at (5,3) {Potential Outcomes};
\draw[->, thick] (5,2.5) -- (5,2.2);
\node at (5,2) {Propensity Score};
\draw[->, thick] (5,1.5) -- (5,1.2);

% Arrow from Orley Ashenfelter and Don Rubin streams to Angrist and Imbens
\draw[->, thick] (-5,1) -- (0,-0.8);
\draw[->, thick] (5,1) -- (0,-0.8);

% Angrist and Imbens node with evenly spaced arrows below them (spacing of 0.5 units)
\node at (0,-1.2) {\textbf{Joshua Angrist} \quad \textbf{Guido Imbens}};
\draw[->, thick] (0,-1.5) -- (0,-1.8); % Arrow from Angrist/Imbens to Harvard Economics
\node at (0,-2.0) {Harvard Economics};
\draw[->, thick] (0,-2.3) -- (0,-2.6); % Arrow from Harvard Economics to Instrumental Variables
\node at (0,-2.8) {Instrumental Variables};
\draw[->, thick] (0,-3.1) -- (0,-3.4); % Arrow from Instrumental Variables to Abadie
\node at (0,-3.6) {\textbf{Alberto Abadie}};
\draw[->, thick] (0,-3.9) -- (0,-4.2); % Arrow from Abadie to Synthetic Control
\node at (0,-4.4) {Synthetic Control};

\end{tikzpicture}
\end{center}


\end{frame}





\section{Foundational ideas}




\begin{frame}{Causal Inference vs Prediction}
  \centering
  \includegraphics[scale=0.5,height=6.5cm, width=10cm]{./lecture_includes/prediction_causality.png}
\end{frame}

\begin{frame}{Causal Inference vs Prediction}

  \begin{columns}
    \column{0.48\linewidth}
    \centering
    \textbf{Traditional prediction}
    \begin{itemize}
      \item Traditional prediction seeks to detect patterns in data and fit functional relationships between variables with a high degree of accuracy
      \item ``Does this person have heart disease?'', ``How many books will I sell?''
      \item It is not predictions of what effect a choice will have, though
    \end{itemize}
    \column{0.48\linewidth}
    \centering
    \textbf{Causal inference}
    \begin{itemize}
      \item Causal inference is also a type of prediction, but it's a prediction of a \emph{counterfactual} associated with a particular \emph{choice taken}
      \item Causal inference takes that predicted (or imputed) counterfactual and constructs a causal effect that we hope tells us about a future in the event of a similar choice taken
    \end{itemize}
  \end{columns}
\end{frame}



\begin{frame}{Naive causal inference}

  \begin{itemize}
    \item Aliens estimate a model showing a systematic correlation between COVID deaths and ventilators
    \item They conclude doctors are killing patients with ventilators so they come to earth to liberate the patients, but it only makes things worse
    \item Their error was they confused correlation with causality, but deeper than that, they didn't understand how the world worked
    \item \emph{We are the aliens in our research}
  \end{itemize}

\end{frame}

\begin{frame}{\#1: Correlation and causality are different concepts}

  Causal is one unit, correlation is many units
  \begin{itemize}
    \item Causal question: ``If a doctor puts a patient on a ventilator (D), will her covid symptoms (Y) improve?''
    \item Correlation question:  $$\frac{Cov(D,Y)}{\sqrt{Var_D}\sqrt{{Var_Y}}}$$
    \item Error extends to predictive modeling that isn't based on causal frameworks
  \end{itemize}

\end{frame}



\begin{frame}{\#2: Coming first may not mean causality!}

  \begin{itemize}
    \item Every morning the rooster crows and then the sun rises
    \item Did the rooster cause the sun to rise? Or did the sun cause the rooster to crow?
    \item What if cat killed the rooster?
    \item \emph{Post hoc ergo propter hoc}: ``after this, therefore, because of this''
  \end{itemize}

\end{frame}

\begin{frame}{\#3: Causality may mask correlations!}

  \begin{figure}
    \centering
    \includegraphics[scale=0.04]{./lecture_includes/scottboat.jpg}
  \end{figure}

\end{frame}


\begin{frame}{Design Stage Flaws}

\begin{itemize}
\item Several studies over the last few years have been documenting a few kinds of problems with empirical work:
	\begin{enumerate}
	\item Malfeasance: Data fabrication
	\item P-hacking bias: Slicing the data up until you find effects
	\item No design stage
	\end{enumerate}
\item We need to figure out what it means to design your studies and how insert that into the projects
\item Think of your study like this: if you asked 100 people to do the study, would they all make the same decisions you made?  Why? 

\end{itemize}

\end{frame}



\begin{frame}{Modeling is Not the First Step}

\begin{itemize}
\item One of the things I will be trying to impress upon you is the idea of the "target parameter" expressed, not as a research question only, but as \emph{averaged} treatment effects over a specific \emph{population}
\item Another is the idea of treatment assignment \emph{mechanisms} -- how and why units are and are not chosen into the treatment versus control status matters for everything
\item I tend to also emphasize shoe leather and slowing down with a long "design stage" that precedes the stage of estimating with data (i.e., coding) and comes after collecting the data
\end{itemize}

\end{frame}

\begin{frame}{Design Stage in Causal Inference}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{./lecture_includes/design_stage.png}
\end{figure}

\end{frame}




\begin{frame}{Definition and Identification Come First}

\begin{enumerate}
\item Turn the research question (``what is the causal effect of an advertising campaign on sales?'') into a specific aggregate causal parameter
\item Describe the narrow set of beliefs that make that parameter obtainable with data
\item Build a model that uses the data and the beliefs to estimate the causal parameter?
\end{enumerate}

\bigskip

Most of us skip (1) and many skip (2) and go straight to (3) but hopefully today I'll convince you that that's how errors are introduced, even after one understands that causal inference is not merely correlational

\end{frame}

\section{Potential Outcomes}

\subsection{History of potential outcomes}



\begin{frame}{Counterfactuals by Philosophers}

\begin{quote}
    ``If a person eats of a particular dish, and dies in consequence, that is, would not have died if he had not eaten it, people would be apt to say that eating of that dish was the source of his death.'' -- John Stuart Mill (19th century moral philosopher and economist)
\end{quote}

\bigskip
  
    \begin{quote}
    ``Causation is something that makes a difference, and the difference it makes must be a difference from what would have happened without it.'' -- David Lewis (20th century philosopher)
\end{quote}

\end{frame}

  


\begin{frame}{Statisticians}

\begin{quote}
``Yet, although the seeds of the idea that [causal effects are comparisons of potential outcomes] can be traced back at least to the 18th century [most likely he means David Hume], the formal notation for potential outcomes was not introduced until 1923 by Neyman.'' -- Don Rubin (1990)
\end{quote}

\end{frame}


\begin{frame}{Jerzy Neyman's Notation}

\begin{itemize}
\item Jerzy Neyman's 1923 masters thesis describes a field experiment with differing plots of land (imagine hundreds of square gardens) and many different ``varieties'' of fertilizer that farmers could apply to the land
\item ``$U_{ik}$ is the yield of the $i$th variety on the $k$th plot...'' (Neyman 1923)
\item He calls $U_{ik}$ ``potential yield'', as opposed to the realized yield because $i$ (the fertilizer type) described all possible fertilizers that could be assigned to each $k$ square garden
\item Though only one fertilizer will be assigned to the land, many possible fertilizer assignments were possible beforehand, each with their own outcome
\end{itemize}

\end{frame}

\begin{frame}{Jerzy Neyman's Notation}

\begin{itemize}

\item For each fertilizer there is an associated ``potential yield'' that he collapses into $U$ which he considers to be ``a priori fixed but unknown'' (Rubin 1990)
\item Farmers draw fertilizer from an urn, like a bingo ball from a bingo ball machine, with replacement and apply it to each square garden
\item Fertilizer assignment moves us from ``all possible outcomes'' to ``realized outcome'' terminology
\item Neyman's urn model was a classic thought experiment, but it was also stochastically identical to the completely randomized experiment
\item His arch-rival, Ronald Fisher, realizes this and publishes a book two years later calling for \emph{randomizization} as the basis for causal inference
\end{itemize}

\end{frame}

\begin{frame}{Treatment assignment mechanism}

\begin{quote}

``Before the 20th century, there appears to have been only limited awareness of the concept of the assignment mechanism.  Although by the 1930s, randomized experiments were firmly established in some areas of scientific investigation, notably in agricultural experiments, there was no formal statement for a general assignment mechanism and, moreover, not even formal arguments in favor of randomization until Fisher (1925).'' (Imbens and Rubin 2015)

\end{quote}

\end{frame}

\begin{frame}

\subsection{Experimental Design Fuses with Quasi-Experimental Design}

\begin{center}
\textbf{Two rivers into causal inference}
\end{center}

\begin{tikzpicture}[scale=0.7, every node/.style={scale=0.7}]
% Orley Ashenfelter Stream
\node at (-5,6) {\textbf{Orley Ashenfelter}};
\draw[->, thick] (-5,5.5) -- (-5,5.2);
\node at (-5,5) {Princeton Industrial Relations Section};
\draw[->, thick] (-5,4.5) -- (-5,4.2);
\node at (-5,4) {Quasi-Experimental Design};
\draw[->, thick] (-5,3.5) -- (-5,3.2);
\node at (-5,3) {David Card};
\draw[->, thick] (-5,2.5) -- (-5,2.2);
\node at (-5,2) {Alan Krueger};
\draw[->, thick] (-5,1.5) -- (-5,1.2);

% Don Rubin Stream
\node at (5,6) {\textbf{Don Rubin}};
\draw[->, thick] (5,5.5) -- (5,5.2);
\node at (5,5) {Harvard Statistics};
\draw[->, thick] (5,4.5) -- (5,4.2);
\node at (5,4) {Experimental Design};
\draw[->, thick] (5,3.5) -- (5,3.2);
\node at (5,3) {Potential Outcomes};
\draw[->, thick] (5,2.5) -- (5,2.2);
\node at (5,2) {Treatment Effects};
\draw[->, thick] (5,1.5) -- (5,1.2);

% Arrow from Orley Ashenfelter and Don Rubin streams to bottom rectangle
\draw[->, thick] (-5,1) -- (0,-0.8);
\draw[->, thick] (5,1) -- (0,-0.8);

% Bottom Rectangle
\node[draw, minimum width=8cm, minimum height=2cm, anchor=north] at (0,-0.8) {
    \begin{tabular}{c}
        Josh Angrist \\
        (Princeton)
    \end{tabular}
    \hspace{2cm}
    \begin{tabular}{c}
        Guido Imbens \\
        (Brown)
    \end{tabular}
};
\node[anchor=north] at (0,-2.8) {\textbf{Harvard Economics}};

\end{tikzpicture}

\end{frame}


\begin{frame}{Background I: Harvard Stats and Potential Outcomes}
  \begin{itemize}
    \item Don Rubin, former chair of Harvard stats, is the main source of potential outcomes, building on Jerzy Neyman's 1923 work.
    \item Rubin's influential 1970s papers advocated for causal inference using contrasts of $Y(1)$ and $Y(0)$.
    \item Neyman's notation, initially in Polish, was translated into English in 1990, likely due to Rubin.
    \item Rubin expanded Neyman's ideas from experiments to observational studies, leading to developments like propensity score methods.
    \item Economics was slow to adopt these methods initially.
  \end{itemize}
\end{frame}


\begin{frame}{Background II: Princeton Industrial Relations Section}
  \begin{itemize}
    \item Late 1970s and early 1980s: little "credibility" in empirical labor studies.
    \item Princeton Industrial Relations Section: older than the economics dept, rigorous, non-partisan focus on US "manpower", highly empirical.
    \item Key faculty are Orley Ashenfelter, David Card, Alan Krueger.
    \item Key students include Bob Lalonde, Josh Angrist, Steve Pischke, John Dinardo, Janet Currie, Anne Case, and many more.
    \item Listen to David Card: \url{https://youtu.be/1soLdywFb_Q?si=BCVqYeRz6jYiwHTQ&t=1580}
  \end{itemize}
\end{frame}


\begin{frame}{Background II: Princeton Industrial Relations Section}
Example of Princeton Paradigm Emerging
  \begin{itemize}
    \item Lalonde (1986) was a groundbreaking study, recently reviewed by Guido Imbens and Yiqing Xu (2024)
    \item Lalonde, a student of Card and Orley, analyzed an RCT on a job training program, finding an average treatment effect of +\$800.
    \item He then replaced the experimental control group with survey data, reran econometric methods, and couldn't replicate the results.
    \item Orley and Card emphasized randomization in their 1985 Restat article, advocating for its exploitation in studies.
  \end{itemize}
\end{frame}


\begin{frame}{IV is Especially Bad}
\begin{itemize}

\item Instrumental variables are like finding a four leaf clover -- you should take it as a good omen
\item It must satisfy several stringent conditions so it's hard to do well
\item But in the old days, people used counterfeit instruments due to low standards which contributed to the empirical crisis
\item Listen to Orley Ashenfelter: \url{https://www.youtube.com/watch?v=GG627T4GbqU}
  \end{itemize}

\end{frame}


\begin{frame}{H. Gregg Lewis on IV}

  \begin{quote}
    "After reviewing virtually every study since 1963, Lewis reached the awkward conclusion that simple OLS of union wage effects were more useful and reliable than those based on IV or endogenous selection approaches. The problem, in his view, was that researchers used arbitrary and unsupported assumptions to identify their models with little or no concern for the validity of their assumptions or the implications of their findings." -- Card (2022)
  \end{quote}

\end{frame}

\begin{frame}{Angrist goes to Harvard}

\begin{itemize}

\item Josh Angrist writes a paper evaluating the effect of military service on career earnings using IV
\item Josh is Card and Orley's student (and Card and Josh win the Nobel prize in 2021 with Imbens)
\item But his instrument is decidedly different -- he uses "actually randomized" instruments.  He uses the draft lottery
\item Finds military services \emph{causes} reductions in career earnings, goes on the Restud tour, gets a job at Harvard

\end{itemize}

\end{frame}

\begin{frame}{Imbens goes to Harvard}

\begin{itemize}

\item Guido Imbens (wins the Nobel with Card and Angrist) is a Dutch econometrics student in a masters program in the UK who follows a professor to Brown for his PhD
\item Very interesting personality -- unusually open minded, non-dogmatic, very intellectually curious
\item \url{https://youtu.be/cm8V65AS5iU?si=FiqecXsH0wjIk9Qc&t=540}
\item He goes to Harvard and overlaps with Angrist for one year
\item Much of what we cover ends up being both parts of this tradition forming a paradigm as well as introducing econometric tools

\end{itemize}

\end{frame}

















\begin{frame}{Progress is made and progress is not made}

\begin{itemize}

\item Part of the fusion between Princeton and Cambridge that I noted was to recast outcomes as potential outcomes, a technical term
\item We need to make a distinction between now the idea of data (``realized outcomes'') and these hypothetical concepts represented by Neyman's notation (``potential outcomes'')
\item Let's introduce potential outcomes and assume an intervention from the pandemic -- 
	\begin{itemize}
	\item Patient is either placed on a ventilator or not ("treatment" is the ventilator)
	\item What effect will it have on their health (e.g., mortality)? 
	\item What is an "effect" and how will we define it?
	\end{itemize}

\end{itemize}


\end{frame}



\begin{frame}{Potential outcomes notation}

Let the treatment be a binary variable: $$D_{i,t} =\begin{cases} 1 \text{ if placed on ventilator at time $t$} \\ 0 \text{ if not placed on ventilator at time $t$} \end{cases}$$where $i$ indexes an individual observation, such as a person
\end{frame}

\begin{frame}{Potential outcomes notation}

Potential outcomes: $$Y_{i,t}^j =\begin{cases} 1 \text{ health if placed on ventilator at time $t$} \\ 0 \text{ health if not placed on ventilator at time $t$} \end{cases}$$where $j$ indexes a potential treatment status for the same $i$ person at the same $t$ point in time
\end{frame}


\begin{frame}{Potential outcomes}

  \begin{itemize}
  \item Prior to being placed on the ventilator, there are multiple possibilities that could happen
		\begin{itemize}
		\item They could be placed on the ventilator, call it $Y^1$, and something could happen, or
		\item They could not be placed on the ventilator, call it $Y^0$, and something could happen
		\end{itemize}
\item There are only two things that could happen because the treatment only has two sides to it -- you either are on it or you aren't
\item Neyman, on the other hand, had an urn consisting of balls representing a large number of treatments (fertilizer types) and so had many potential outcomes

\end{itemize}

\end{frame}

\begin{frame}{Potential outcomes vs realized outcomes}
	\begin{itemize}
	\item Experimentalists thought of potential outcomes as "real" in that either of those beforehand could happen -- Rubin "a priori fixed by unknown"
	\item But once the decision to put the patient on the ventilator happens, it eliminates one of them, and that's the difference between potential outcomes and realized outcomes
	\item Potential outcomes are more or less describing what would happen under different treatments, but realized outcomes are describing what did in fact happen for a given treatment
  \end{itemize}
\end{frame}


\begin{frame}{Treatment Assignment Mechanism }

\begin{itemize}
\item The second part of causal inference in the design tradition has to do with the reason that a person gets on a ventilator
\item Did a doctor choose to do it?  Did the patient choose to do it?  Did an algorithm choose to do it?
\item But it's more than that -- \emph{why} was the choice made, not \emph{who} made it
\item For instance, a doctor might always make it, but it matters if she flipped a coin vs read the chart and made the "best decision"
\end{itemize}
\end{frame}

\begin{frame}{Important definitions}

    \begin{block}{Definition 1: Individual treatment effect}
      The individual treatment effect,  $\delta_i$, associated with a ventilator is equal to $Y_i^1-Y_i^0$.
    \end{block}
\end{frame}


\begin{frame}{Important definitions}


    \begin{block}{Definition 2: Switching equation}
      An individual's realized health outcome, $Y_i$, is determined by treatment assignment, $D_i$ which selects one of the potential outcomes:
      \begin{eqnarray*}
        Y_i& = D_iY^1_i+(1-D_i)Y^0_i& \\
        Y_i& = \begin{cases}
          Y^1_i\text{ if }D_i=1 \\
          Y^0_i\text{ if }D_i=0
        \end{cases}
      \end{eqnarray*}
    \end{block}
    
    Not the same as treatment assignment mechanism.  Treatment assignment mechanism describes why one patient but not another was put on the ventilator

\end{frame}


\begin{frame}{Missing data problem}


    \begin{block}{Definition 3: Fundamental problem of causal inference}
      If you need both potential outcomes to know causality with certainty, then since it is impossible to observe both $Y_i^1$ and $Y_i^0$ for the same individual, $\delta_i$, is \emph{unknowable}.
    \end{block}

This is my reason from saying Mill's counterfactual framework derailed the quest for causal effects given counterfactuals are fictional
    
\end{frame}

\begin{frame}{Missing data problem}


    
    \begin{itemize}
    \item Fundamental problem of causal inference is deep and impossible to overcome -- not even with more data (you will always with more data be missing one of the potential outcomes)
    \item Causal inference is a missing data problem 
    \item All of causal inference involves imputing missing counterfactuals and not all imputations are equal
  \end{itemize}

    
\end{frame}




\begin{frame}{Average Treatment Effects}

  \begin{block}{Definition 4: Average treatment effect (ATE)}
    The average treatment effect is the population average of all $i$ individual treatment effects
    \begin{eqnarray*}
      E[\delta]&=&E[Y^1-Y^0]\\
      &=&E[Y^1] - E[Y^0]
    \end{eqnarray*}
  \end{block}

  \bigskip

Aggregate parameters based on individual treatment effects are \emph{summaries} of individual treatment effects

\bigskip

  Cannot be calculated because $Y^1_i$ and $Y^0_i$ do not exist \emph{for the same unit i} due to switching equation

\end{frame}



\begin{frame}{Conditional Average Treatment Effects}


  \begin{block}{Definition 5: Average Treatment Effect on the Treated (ATT)}
    The average treatment effect on the treatment group is equal to the average treatment effect conditional on being a treatment group member:
    \begin{eqnarray*}
      E[\delta|D=1]&=&E[Y^1-Y^0|D=1] \nonumber \\
      &=&E[Y^1|D=1]-E[Y^0|D=1]
    \end{eqnarray*}
  \end{block}
  Cannot be calculated because $Y^1_i$ and $Y^0_i$ do not exist \emph{for the same unit i} due to switching equation. 


\end{frame}



\begin{frame}{Conditional Average Treatment Effects}

  \begin{block}{Definition 6: Average Treatment Effect on the Untreated (ATU)}
    The average treatment effect on the untreated group is equal to the average treatment effect conditional on being untreated:
    \begin{eqnarray*}
      E[\delta|D=0]&=&E[Y^1-Y^0|D=0] \nonumber \\
      &=&E[Y^1|D=0]-E[Y^0|D=0]
    \end{eqnarray*}
  \end{block}
  Cannot be calculated because $Y^1_i$ and $Y^0_i$ do not exist \emph{for the same unit i} due to switching equation

\end{frame}


\begin{frame}{Average Treatment Effects are Simple Summaries}

  \begin{itemize}
	\item Notice how in all three of these, all we did was take the defined treatment effect at the individual and aggregate
	\item Because aggregate causal parameters are \emph{summaries} of individual treatment effects, each of which cannot be calculated, the aggregates cannot be calculated either
	\item Missing data in this context isn't missing your car keys -- it's missing unicorns and fire breathing dragons (fictional vs real data)
	\item While we cannot measure average causal effects, we can estimate them, but only in situations and we review one -- randomization
  \end{itemize}

\end{frame}







\begin{frame}{Simple Comparisons}



  \begin{block}{Definition 7: Simple difference in mean outcomes (SDO)}
    A simple difference in mean outcomes (SDO) can be approximated by comparing the sample average outcome for the treatment group ($D=1$) with a comparison group ($D=0$)
    
    \begin{eqnarray*}
      SDO &=& E[Y^1 | D=1] - E[Y^0 | D=0]
    \end{eqnarray*}
  \end{block}
  \bigskip

SDO is not a causal parameter because it's comparing $Y^1$ and $Y^0$ for different units, not the same units, so what is it measuring? 

\end{frame}


\begin{frame}{Decomposition of the SDO}

  \begin{block}{Decomposition of the SDO}
    The SDO is made up of three things:
    \begin{eqnarray*}
      E[Y^1 | D=1] - E[Y^0 | D=0]&=& ATE\nonumber \\
      &&+ E[Y^0|D=1] - E[Y^0|D=0] \nonumber \\
      && + (1-\pi)(ATT - ATU)
    \end{eqnarray*}
  \end{block}

\bigskip

where $\pi$ is the share of units in the treatment group.  Now let's see how we get here.
\end{frame}

\begin{frame}{Two ways to rewrite the ATE}

\begin{itemize}
\item Before we get started, let's look closely at the definition of the ATE
	\begin{itemize}
	\item We can express the ATE as the weighted average of the ATT and the ATU, and \dots
	\item We can express the ATE as the sum of four conditional means multiplied by corresponding weights (Law of iterated expectations)
	\end{itemize}
\item They are in fact the exact same formula once you write down the definition of the ATT and the ATU
\item Let's do it together before we get started: \url{https://docs.google.com/spreadsheets/d/10DuQqGtH_Ewea7zQoLTFYHbnvqaTVDhn2GDzq3Oa6EQ/edit?usp=sharing}

\end{itemize}

\end{frame}


\begin{frame}{Begin with ATE definition}

  \begin{block}{Rewrite the definition of the ATE}
    \begin{eqnarray*}
      \text{ATE}&=&E[Y^1]-E[Y^0]  \\
      &=& \pi ATT + (1-\pi) ATU \\
      &=& \pi E[Y^1 | D=1] - \pi E[Y^0 | D=1]  \\
      & & + (1-\pi) E[Y^1|D=0] - (1-\pi) E[Y^0 | D=0] \\
      \text{ATE}&=& \{\pi E[Y^1 | D=1] + (1-\pi)E[Y^1 | D=0]\}  \\
      & & - \{\pi E[Y^0|D=1] + (1-\pi) E[Y^0 | D=0]\}
    \end{eqnarray*}
  \end{block}

\bigskip

Let's make this easier to read by replacing the last row with letters

\end{frame}

\begin{frame}{Change notation}



  \begin{block}{Substitute letters for expectations}
    \begin{eqnarray*}
      E[Y^1|D=1] &=& a  \\
      E[Y^1|D=0] &=& b  \\
      E[Y^0|D=1] &=& c  \\
      E[Y^0|D=0] &=& d  \\
      \text{ATE} &=& e
    \end{eqnarray*}
  \end{block}
  



\end{frame}

\begin{frame}{Rewrite ATE definition}


  \begin{block}{Rewrite ATE}
    \begin{eqnarray*}
      e&=&\{\pi{a} + (1-\pi)b\} - \{\pi{c} + (1-\pi)d\}
    \end{eqnarray*}
  \end{block}

\end{frame}




\begin{frame}[plain]

  \begin{block}{Simple manipulation of ATE definition}
    \begin{eqnarray*}
      e&=&\{\pi{a} + (1-\pi)b\} - \{\pi{c} + (1-\pi)d\}  \\
      e&=&\pi{a} + b - \pi{b} - \pi{c} - d + \pi{d}  \\
      e&=&\pi{a} + b - \pi{b} - \pi{c} - d + \pi{d} + (\textbf{a} - \textbf{a}) + (\textbf{c} - \textbf{c}) + (\textbf{d} - \textbf{d})  \\
      0&=&e-\pi{a} - b + \pi{b} + \pi{c} + d - \pi{d} - \textbf{a} + \textbf{a} - \textbf{c} + \textbf{c} - \textbf{d} + \textbf{d}  \\
      \textbf{a}-\textbf{d}&=&e-\pi{a} - b + \pi{b} + \pi{c} + d - \pi{d}  + \textbf{a} - \textbf{c} + \textbf{c} - \textbf{d}  \\
      \textbf{a}-\textbf{d}&=&e  + (\textbf{c} - \textbf{d}) + \textbf{a}-\pi{a} - b + \pi{b} - \textbf{c} + \pi{c} + d - \pi{d} \\
      \textbf{a}-\textbf{d}&=&e  + (\textbf{c} - \textbf{d}) + (1-\pi)a -(1-\pi)b + (1-\pi)d - (1-\pi)c  \\
      \textbf{a}-\textbf{d}&=&e  + (\textbf{c} - \textbf{d}) + (1-\pi)(a-c) -(1-\pi)(b-d)
    \end{eqnarray*}
  \end{block}


\end{frame}

\begin{frame}[shrink=20,plain]
  \begin{block}{Carry forward from previous slide}
    \begin{eqnarray*}
      \textbf{a}-\textbf{d}&=&e  + (\textbf{c} - \textbf{d}) + (1-\pi)(a-c) -(1-\pi)(b-d)
    \end{eqnarray*}
  \end{block}

  \begin{block}{Replace letters with original terms }
    \begin{eqnarray*}
      E[Y^1|D=1] - E[Y^0|D=0] &=& \alert{\text{ATE}}  \\
      &&+ (\alert{E[Y^0|D=1]} - E[Y^0|D=0])  \\
      && + (1-\pi)( \underbrace{\{E[Y^1|D=1] - \alert{E[Y^0|D=1]}\}}_{ \mathclap{\text{ATT}}}  \\
      && - (1-\pi)( \underbrace{\{\alert{E[Y^1|D=0]} - {E[Y^0|D=0]}\}}_{ \mathclap{\text{ATU}}}  \\
    \end{eqnarray*}
  \end{block}
  
$\alert{\text{Purple terms}}$ are based on missing counterfactuals and therefore cannot be calculated. This is an \emph{identity}
  
\end{frame}

\begin{frame}{Decomposition of the SDO}

  \begin{block}{Decomposition of the SDO}
    \begin{eqnarray*}
      E[Y^1 | D=1] - E[Y^0 | D=0]  &=& \alert{ATE} \\
      &&+ (\alert{E[Y^0|D=1]} - E[Y^0|D=0])  \\
      && + (1-\pi)(\alert{ATT - ATU})
    \end{eqnarray*}
  \end{block}
  
  \bigskip
  
Although we started with $\pi$ (the share of units in treatment), note we have weighted the heterogeneity bias term by $1-\pi$ (the share of units in control)
\end{frame}


\begin{frame}[plain]

  \begin{block}{Estimate SDO with sample averages}
    \begin{eqnarray*}
      \underbrace{E_N[Y | D=1] - E_N[Y | D=0]}_{ \mathclap{\text{Estimate of SDO}}}&=& \underbrace{E[Y^1] - E[Y^0]}_{ \mathclap{\text{Average Treatment Effect}}} \\
      &&+ \underbrace{\alert{E[Y^0|D=1]} - E[Y^0 | D=0]}_{ \mathclap{\text{Selection bias}}}  \\
      && + \underbrace{(1-\pi)(ATT - ATU)}_{ \mathclap{\text{Heterogenous treatment effect bias}}}
    \end{eqnarray*}
  \end{block}

\bigskip

Using the switching equation and sample averages, we can calculate $E_N[Y|D=1] \to E[Y^1 | D=1]$, $E_N[Y|D=0] \to E[Y^0|D=0]$ and $(1-\pi)$ is the share of the population in the control group.

\end{frame}

\begin{frame}{Illustrating selection bias with spreadsheets}
\begin{itemize}
\item Eliminating selection bias requires understanding the selection mechanism -- why did units end up treated but not others?
\item Perfect Doctor exercise: assume a doctor sees patients, knows each person's treatment effects, despite counterfactuals, and assigns treatment based on whether gains are positive or not
\item Illustrate decomposition together using numerical example: \url{https://docs.google.com/spreadsheets/d/10DuQqGtH_Ewea7zQoLTFYHbnvqaTVDhn2GDzq3Oa6EQ/edit?usp=sharing}
\end{itemize}
\end{frame}


\section{Independence and Selection Bias}





\begin{frame}{Design vs model based approaches to selection bias}

\begin{itemize}

\item Historically two ways that this selection bias was addressed: modeling it directly (Heckman, and others) and by design (Rubin, Princeton)
	\begin{enumerate}
	\item Design-based methods.  Experimental design and randomization
	\item Model-based methods.  Model the selection bias and then remove it mechanically
	\end{enumerate}
\item Both have been highly influential, but constitute different approaches, and our workshop largely focuses on the former not the latter

\end{itemize}

\end{frame}





\begin{frame}{Selection bias and Design}

\begin{itemize}
\item Selection bias in causal inference is when one or both mean potential outcome differ by treatment status
\item Source of the bias is caused by the why people get treated, or what's called the ``treatment assignment \emph{mechanism}''
\item But as we will see, if the treatment was assigned randomly (exogeneity), the implications differ than if they were assigned "optimally" (endogeneity)


\end{itemize}

\end{frame}

\begin{frame}{Treatment assignment mechanisms}

\begin{itemize}
\item Two extreme examples of a treatment assignment mechanism: 
	\begin{enumerate}
	\item randomization (i.e., taking the medicine because a coin flip told you to take it) versus 
	\item sorting on one or both potential outcome (i.e., taking the medicine because it'll help you) which I call the ``Perfect Doctor'' but which Heckman and others call a ``Roy model''
	\end{enumerate}
\item Bias comes from how treatment is assigned and that mechanism dictates the direction we have to take

\end{itemize}

\end{frame}


\begin{frame}{Three forms of selection bias}

  \begin{itemize}
    \item In causal inference, selection bias is caused by different mean potential outcomes by treatment status, of which there are three possibilities:
		\begin{enumerate}
   \item Selection on $Y^0$: You chose the treatment because of what will happen if you didn't
    \item Selection on $Y^1$: You chose the treatment because of what will happen if you do
    \item Selection on gains, $\delta$: You chose the treatment because the net benefits were positive
    	\end{enumerate}
	\item All three cause biased estimates of the ATE, though the degree to which it fully distorts the estimates depends on those different reasons for sorting into treatment
      \end{itemize}

\end{frame}



\begin{frame}{Humans cause selection bias, not models}

\begin{itemize}
\item An unusual paradox in causal inference is that our successful programs are the hardest to study:
	\begin{itemize}
	\item The better our programs are, the better humans get at assigning treatments to people, the more interventions target people correctly based on treatment gains, the worse the selection bias is
	\item But the less efficient our programs, the more erratic the assignment mechanism is, the more mistakes there are in targeting people with their best options, the less the selection bias is
	\end{itemize}
\item The reason for the ``natural experiment'' drive in causal inference was based on what we could deduce about selection bias from designs, which was more like the latter
\item But solely depending on the latter would be limiting if our aim was to study our most successful programs (e.g., food stamps or STAMP)
\end{itemize}

\end{frame}













\begin{frame}{Summarizing the goals of causal inference}

  Our goal in causal inference is to estimate aggregate causal parameters with data using treatment assignment mechanisms that plausibly eliminate selection bias

  \bigskip

Depending on the treatment assignment mechanism, certain procedures are allowed and others are prohibited

  \bigskip

  Let's look what happens in an RCT \emph{and why} this addresses selection bias term $\alert{E[Y^0|D=1]}$ and $E[Y^0|D=0]$ to see why Fisher (1925) recommended it

\end{frame}


\begin{frame}{Independence}


  \begin{block}{Independence assumption}
    Treatment is assigned to a population independent of that population's potential outcomes  $$(Y^0,Y^1)\independent{D}$$
  \end{block}
  This is random or quasi-random assignment and ensures mean potential outcomes for the treatment group and control group are the same.  Also ensures other variables are distributed the same for a large sample.
  \begin{eqnarray*}
    \alert{E[Y^0|D=1]} &=& E[Y^0 | D=0] \\
    E[Y^1|D=1] &=& \alert{E[Y^1 | D=0]}
  \end{eqnarray*}
\end{frame}

\begin{frame}{Random Assignment Solves the Selection Problem}

  \begin{eqnarray*}
    \underbrace{E_N[y_i | d_i=1] - E_N[y_i | d_i=0]}_{ \mathclap{\text{SDO}}}&=& \underbrace{E[Y^1] - E[Y^0]}_{ \mathclap{\text{Average Treatment Effect}}} \\
    &&+ \underbrace{E[Y^0|D=1] - E[Y^0 | D=0]}_{ \mathclap{\text{Selection bias}}}  \\
    && + \underbrace{(1-\pi)(ATT - ATU)}_{ \mathclap{\text{Heterogenous treatment effect bias}}}
  \end{eqnarray*}


  \begin{itemize}
    \item If treatment is independent of potential outcomes, then swap out equations and \textbf{selection bias} zeroes out:
          \begin{eqnarray*}
            E[Y^0 | D=1] - E[Y^0 | D=0] &=& 0
          \end{eqnarray*}
  \end{itemize}

\end{frame}

\begin{frame}[shrink=20,plain]
  \begin{center}
    \textbf{Random Assignment Solves the Heterogenous Treatment Effects}
  \end{center}

  \begin{itemize}
    \item How does randomization affect heterogeneity treatment effects bias from the third line?  Rewrite definitions for ATT and ATU:\begin{eqnarray*}
            \text{ATT} = E[Y^1 | D=1] - E[Y^0 | D=1] \\
            \text{ATU} = E[Y^1 | D=0] - E[Y^0 | D=0] \\
          \end{eqnarray*}
    \item Rewrite the third row bias after $1-\pi$:\begin{eqnarray*}
            ATT - ATU &=& \textbf{E[Y$^1$ $|$ D=1]} - E[Y^0 | D=1] \\
            && - \textbf{E[Y$^1$ $|$ D=0]} + E[Y^0 | D=0] \\
            &=& 0
          \end{eqnarray*}
    \item If treatment is independent of potential outcomes, then:\begin{eqnarray*}
            E_N[y_i | d_i=1] - E_N[y_i | d_i=0]  &=& E[Y^1] - E[Y^0] \\
            SDO &=& ATE
          \end{eqnarray*}
  \end{itemize}
\end{frame}






\begin{frame}[plain]

  \begin{block}{Identification with Full Independence}
    \begin{eqnarray*}
      \underbrace{E_N[Y_i | D_i=1] - E_N[Y_i | D_i=0]}_{ \mathclap{\text{Estimate of SDO}}}&=& \underbrace{E[Y^1] - E[Y^0]}_{ \mathclap{\text{Average Treatment Effect}}} \\
    &&+ \underbrace{0}_{ \mathclap{\text{Selection bias}}}  \\
    && + \underbrace{0}_{ \mathclap{\text{Heterogenous treatment effect bias}}}
    \end{eqnarray*}
  \end{block}
  
  SDO is unbiased estimate of ATE with randomized treatment assignment because it sets selection bias to zero and $ATT=ATU$.



\end{frame}

\begin{frame}{What about partial independence?}

  \begin{itemize}
  \item For homework, write down the independence terms and substitute it into the decomposition if selection into treatment is independent of $Y^0$ but not $Y^1$
  \item What if it is independent of $Y^0$ but not $Y^1$?
  \item Can you describe formally the bias caused by partial independence?  What terms are eliminated?  What terms remain?
  \item We will review it tomorrow
  \end{itemize}
\end{frame}




\begin{frame}{Interference when aggregating units}

\begin{itemize}
\item While treatment effects are defined at individual level, aggregate parameters combine units
\item This therefore means that for the aggregate parameters to be stable, one unit's treatment choice cannot ``interfere'' with another unit's potential outcomes
\item Placing limits on those possibilities creates challenges for definitions and estimation that are probably huge headaches, even in the RCT
\item Violations are an active area of scholarship and important for social networks, peer effects and various platforms (e.g., Twitter)
\end{itemize}

\end{frame}

\begin{frame}{SUTVA}

  \begin{itemize}
    \item SUTVA stands for ``stable unit-treatment value assumption''
          \begin{enumerate}
            \item \textbf{S}: \emph{\textbf{s}table}
            \item \textbf{U}: across all \emph{\textbf{u}nits}, or the population
            \item \textbf{TV}: \emph{\textbf{t}reatment-value} (``treatment effect'', ``causal effect'')
            \item \textbf{A}: \emph{\textbf{a}ssumption}
          \end{enumerate}
    \item Means that a potential outcome has nothing to do with others' treatment assignment -- only one's own, and only today
  \end{itemize}
\end{frame}


\begin{frame}{No spillovers to other units}

  \begin{itemize}
    \item What if we impose a treatment at one neighborhood but not a contiguous one?
    \item Treatment may spill over causing $Y=Y^1$ even for the control units because of spillovers from treatment group
    \item Can be mitigated with careful delineation of treatment and control units so that interference is impossible, may even require aggregation (e.g., classroom becomes the unit, not students)
  \end{itemize}
\end{frame}



\begin{frame}{No Hidden Variation in Treatment}

  \begin{itemize}
    \item SUTVA requires each unit receive the same treatment dosage; this is what it means by ``stable'' (i.e., notice that the super scripts contain either 0 or 1, not 0.55, 0.27)
    \item If we are estimating the effect of aspirin on headaches, we assume treatment is 200mg per person in the treatment
    \item Easy to imagine violations if hospital quality, staffing or even the vents themselves vary across treatment group
    \item Be careful what we are and are not defining as \emph{the treatment}; you may have to think of it as multiple arms
  \end{itemize}
\end{frame}

\begin{frame}{Scale can affect stability of treatment effects}

  Easier to imagine this with a different example.
  \begin{itemize}
    \item Let's say we estimate a causal effect of early childhood intervention in Texas
    \item Now President Biden wants to roll it out for the whole United States -- will it have the same effect as we found?
    \item Scaling up a policy can be challenging to predict if there are rising costs of production
    \item What if expansion requires hiring lower quality teachers just to make classes?
    \item That's a general equilibrium effect; we only estimated a partial equilibrium effect (external versus internal validity)
  \end{itemize}
\end{frame}



\section{Industry example of RCT: eBay advertising}

\begin{frame}

\begin{figure}[hpt]
\begin{center}
\includegraphics[scale=0.25]{./lecture_includes/econometrica_steve.png}
\end{center}
\end{figure}

\end{frame}

\begin{frame}{Internet advertising facts}

\begin{itemize}
\item In 2012, revenues from Internet advertising was \$36.6 billion and has only grown since
\item Paid search (``search engine marketing'') is the largest format by revenue (46.3\% of 2012 revenues, or \$16.9 billion)
\item Google is leading provider (registered \$46 billion in global revenues in 2012 of which 95\% was attributed to advertising)
\end{itemize}

\end{frame}

\begin{frame}{Selection bias}

\begin{itemize}
\item Treatment was targeted ads at particular people conducting particular types of keyword search
\item Consumers who choose to click on ads are loyal and already informed about products with high likelihood to buy already 
\item Problem is ads are targeting people at the end of their search, so the question is whether they would've found it already (i.e., $E[Y^0|D=1] \neq E[Y^0|D=0]$)
\end{itemize}


\end{frame}



\begin{frame}{Selection bias}

\begin{itemize}
\item Estimated return on investment using OLS  found ROI of over 1600\%
\item Compared this to experimental methods and found ROI of -63\% with a 95\% CI of $[-124\%, -3\%]$, rejecting the hypothesis that the channel yielded short-run positive returns
\item Think back to perfect doctor -- Even without the treatment ($Y^0$), the treated group observationally would've still found a way
\end{itemize}

\end{frame}

\begin{frame}{Natural experiment}

\begin{itemize}
\item Study began with a naturally occurring and somewhat fortuitous  event at eBay
\item eBay halted SEM queries for brand words (i.e., queries that included the term eBay) on Yahoo! and Microsoft but continued to pay for these terms on Google
\item Blake, Nosky and Tadelis (2015) showed almost all of the foregone click traffic and attributed sales were captured by natural search
\item Substitution between paid and unpaid traffic was nearly one to one complete
\end{itemize}

\end{frame}


\begin{frame}

\begin{figure}
\begin{center}
\includegraphics[scale=0.2]{./lecture_includes/tadelis_fig1.png}
\end{center}
\end{figure}

\end{frame}

\begin{frame}{Interpretation of natural experiment}

\begin{quote}
``The evidence strongly supports the intuitive notion that for brand keywords, natural search is close to a perfect substitute for paid search, making brand keyword SEM ineffective for short-term sales.  After all, the users who type the brand keyword in the search query intend to reach the company's website, and most likely will execute on their intent regardless of the appearance of a paid search ad.''
\end{quote}

\end{frame}

\begin{frame}{Selection bias}

Observational data masked causal effect (recall the decomposition of the any non-designed estimation strategy)

\bigskip

\begin{quote}
``Advertising may appear to attract these consumers, when in reality they would have found other channels to visit the company's website.  We overcome this endogeneity challenge with our controlled experiments.''
\end{quote}

\end{frame}




\begin{frame}{RCT}

Natural experiment was valuable, but eBay could run a large scale RCT.

\bigskip


Use this finding of a nearly one-to-one substitution once paid search was dropped to convince eBay to field a large scale RCT discontinuing non-band key words

\bigskip


\end{frame}

\begin{frame}{Design of the experiment}

\begin{itemize}
\item Randomly assigned 30 percent of eBay's US traffic to stop all bidding for all non-brand keywords for 60 days
\item Some random group of users, in other words, were exposed to ads; a control group did not see the ads
\item Used Google's geographic bid feature that can accurately identify geographic market of the user conducting the search
\item Ads were suspended in 30 percent of markets to reduce the scope of the test and minimize the potential cost and impact to the business
\end{itemize}

\end{frame}

\begin{frame}

\begin{figure}
\begin{center}
\includegraphics[scale=0.2]{./lecture_includes/tadelis_fig3.png}
\caption{Attributed sales due to clicking on a Google link (treatment group)}
\end{center}
\end{figure}

\end{frame}


\begin{frame}

\begin{figure}
\begin{center}
\includegraphics[scale=0.2]{./lecture_includes/tadelis_fig2.png}
\caption{Differences in total sales by market (treatment to control)}
\end{center}
\end{figure}

\end{frame}

\begin{frame}

\begin{figure}
\begin{center}
\includegraphics[scale=0.2]{./lecture_includes/tadelis_ols1.png}
\caption{Spending effect on revenue using OLS but not the randomization. Effects are gigantic. }
\end{center}
\end{figure}

\end{frame}

\begin{frame}

\begin{figure}
\begin{center}
\includegraphics[scale=0.2]{./lecture_includes/tadelis_ols2.png}
\caption{Spending effect on revenue using the randomization. Effects are negative. }
\end{center}
\end{figure}

\end{frame}

\begin{frame}{Heterogenous treatment effects}

\begin{itemize}
\item Recall how the potential outcomes model explicitly models individual treatment effects could be unique and that the perfect doctor showed selection on gains masked treatment effects, perhaps even reversing sign
\item Search advertising in this RCT only worked if the consumer had no idea that the company had the desired product
\item Large firms like eBay with powerful brands will see little benefit from paid search advertising because most consumers already know that they exist, as well as what they have to offer
\end{itemize}

\end{frame}


\begin{frame}

\begin{figure}
\begin{center}
\includegraphics[scale=0.2]{./lecture_includes/tadelis_newuser_fig1.png}
\caption{Effects on new users are positive and large, but not others. }
\end{center}
\end{figure}

\end{frame}

\begin{frame}

\begin{figure}
\begin{center}
\includegraphics[scale=0.2]{./lecture_includes/tadelis_newuser_fig2.png}
\caption{Effects are largest for ``least active'' customers. }
\end{center}
\end{figure}

\end{frame}


\begin{frame}{Why are causal effects small?}

\begin{itemize}
\item They suggest that the brand query tests found small causal returns because users simply substituted from the paid search clicks to the natural search clicks
\item If that's the case, then it's explicitly a selection bias story $$E[Y^0|D=1] \neq E[Y^0|D=0]$$ where $D$ is being shown the branded advertisement based on search (i.e., they were already going there)
\item They weren't using branded search for information; they were using to \emph{navigate}
\end{itemize}

\end{frame}

\begin{frame}{Self selection based on gains}

\begin{itemize}
\item Potential outcomes is the foundation of the physical experiment because the physical experiment assigns units to treatments \emph{independent} of potential outcomes, $Y^0,Y^1$
\item This is important because outside of the physical experiment, we expect people select those important treatments based on whether, subjectively, they think $Y^1>Y^0$ or $Y^1\leq Y^0$. 
\item Rational actors almost by definition are thought to ``self-select into treatment'' making non-designed comparisons potentially misleading -- sometimes by a little, sometimes by a lot
\end{itemize}

\end{frame}

\section{Tennessee's small class size RCT: STAR}

\begin{frame}[plain]
	\begin{center}
	\textbf{Example 1: Krueger (1999)}
	\end{center}
	
	\begin{itemize}
	\item Krueger (1999) econometrically re-analyzes a randomized experiment to determine the causal effect of class size on student achievement
	\item The project is the Tennessee Student/Teacher Achievement Ratio (STAR) experiment from the 1980s
	\item 11,600 students and their teachers were \emph{randomly} assigned to one of the following three groups:
		\begin{enumerate}
		\item Small class of 13-17 students
		\item Regular class of 22-25 students
		\item Regular class of 22-25 students with a full-time teacher's aide
		\end{enumerate}
	\item After the assignment, the design called for students to remain in the same class type for four years
	\item Randomization occurred within schools
	\end{itemize}
\end{frame}

\begin{frame}[plain,shrink=20]
	\begin{center}
	\textbf{Regression analysis of experiments}
	\end{center}
	
	\begin{itemize}
	\item With randomization one could simply calculate SDO (simple difference in mean outcomes) for the treatment and control group and know that SDO$=$ATE because of independence
	\item Nonetheless, it is often useful to analyze experimental data with regression analysis (see MW section 3.2.2; MHE ch. 2)
	\item Assume that treatment effects are constant -- i.e., $Y^1_i - Y^0_i=\delta$  $\forall i$
	\item Substitute into a rearranged switching equation (Definition 2):
		\begin{eqnarray*}
		Y_i &=& D_iY_i^1 + (1-D_i)Y^0_i \\
		Y_i &=& Y^0_i + (Y^1_i-Y^0_i)D_i \\
		Y_i &=& Y^0_i + \delta D_i  \\
		Y_i &=&E[Y^0_i] + \delta D_i+ Y_i^0 - E[Y_i^0] \\
		Y_i &=& \alpha + \delta D_i + \eta_i
		\end{eqnarray*}where $\eta_i$ is the random part of $Y_i^0$
	\item This is a regression equation that could be used to estimate the causal effect of $D$ on $Y$
	\end{itemize}
\end{frame}

\begin{frame}[plain]
	\begin{center}
	\textbf{Regression analysis of experiments (cont.)}
	\end{center}
	
	\begin{itemize}
	\item The conditional expectation, $E[Y_i|D_i]$, with treatment status switched on and off gives:
		\begin{eqnarray*}
		E[Y_i | D_i=1] &=& \alpha + \delta + E[\eta_i | D_i=1] \\
		E[Y_i | D_i=0] &=& \alpha + E[\eta_i | D_i=0]
		\end{eqnarray*}
	\item Subtracting the latter from the former, we get:
		\begin{eqnarray*}
		 \underbrace{E[Y_i | D_i=1]  - E[Y_i | D_i=0]}_{ \mathclap{\text{SDO}}} &=& \underbrace{\delta}_{ \mathclap{\text{Treatment Effect}}}\\
		 &&+  \underbrace{E[\eta_i | D_i=1] - E[\eta_i | D_i=0]}_{ \mathclap{\text{Selection bias}}}
		\end{eqnarray*}
	\end{itemize}
\end{frame}

\begin{frame}[plain]

\begin{itemize}
	\item We can estimate $SDO$ using least squares but there's other options as well
	\item In the STAR experiment, $D_i$, equalled one if the student was enrolled in a small class and had been \emph{randomly} assigned
	\item Recall that randomization implies that treatment is independent of potential outcomes, and therefore the selection bias vanishes
\end{itemize}
\end{frame}

\begin{frame}[plain]
	\begin{center}
	\textbf{Why Include Control Variables?}
	\end{center}
	
	\begin{itemize}
	\item To evaluate experimental data, one may want to add additional controls in the multivariate regression model.  So, instead of estimating the prior equation, we might estimate:
		\begin{eqnarray*}
		Y_i = \alpha + \delta D_i + X_i'\gamma + \eta_i
		\end{eqnarray*}
	\item There are 2 main reasons for including additional controls in the regression models:
		\begin{enumerate}
		\item Conditional random assignment.  Sometimes randomization is done \emph{conditional} on some observable.  (here that's the school).  We'll discuss ``conditional independence assumption'' when we cover matching.
		\item Additional controls increase precision.  Although control variables $X_i$ are uncorrelated with $D_i$, they may have substantial explanatory power for $Y_i$. Including controls thus reduces variance in the residuals which lowers the standard errors of the regression estimates.
		\end{enumerate}
	\end{itemize}
\end{frame}

\begin{frame}[plain]
	\begin{center}
	\textbf{Regression in Krueger (1999)}
	\end{center}
	
Krueger estimates the following econometric model$$Y_{ics} = \beta_0 + \beta_1 SMALL_{cs} + \beta_2 \text{REG/A}_{cs} + \alpha_s + \varepsilon_{ics}$$\begin{itemize}\item $i$ indexes a student, $c$ indexes a class, and $s$ indexes a school
		\item $Y_{ics}$ is the student's percentile score
		\item $SMALL_{cs}$ is a dummy equalling 1 if she is assigned to a small class.
		\item $REG/A_{cs}$ is a dummy equalling 1 if she was assigned to a regular class with an aide
		\item $\alpha$ is a ``school fixed effect'' which is a vector of school-specific dummy variables.  He conditions on school fixed effects because randomized classroom assignment occurred \emph{within} schools. 
		\end{itemize}
\end{frame}

\begin{frame}[plain]
	\begin{center}
	\textbf{Regression results Kindergarten}
	\end{center}
	
	\begin{figure}
	\includegraphics{./lecture_includes/krueger1999_table5a.pdf}
	\end{figure}
\end{frame}


\begin{frame}[plain]
	\begin{center}
	\textbf{Regression results 1st grade}
	\end{center}
	
	\begin{figure}
	\includegraphics{./lecture_includes/krueger1999_table5b.pdf}
	\end{figure}
\end{frame}

\begin{frame}[plain]
	\begin{center}
	\textbf{Problem 1: Attrition}
	\end{center}
	
A common problem in randomized experiments on humans is \emph{attrition} -- i.e., people leaving the experiment
	\begin{itemize}		
	\item If attrition is random, then attrition affects the treatment and control groups in the same way and our estimates remain unbiased
	\item But in this application, attrition is probably non-random: especially good students from large classes may have enrolled in private schools creating a selection bias problem
	\item Krueger addresses this concern by imputing the test scores (from their earlier test scores) for all children who leave the sample and then re-estimates the model including students with imputed test scores.
	\end{itemize}
\end{frame}

\begin{frame}[plain, shrink=20]
	\begin{center}
	\textbf{Problem 1: Attrition}
	\end{center}
	
	\begin{figure}
	\includegraphics{./lecture_includes/krueger1999_table6.pdf}
	\end{figure}
	
	\begin{itemize}
	\item Non-random attrition hardly biases the results.
	\end{itemize}
\end{frame}

\begin{frame}[plain]
	\begin{center}
	\textbf{Problem 2: Switch Classrooms after Random Assignment}
	\end{center}

``It is virtually impossible to prevent some students from switching between class types over time.'' (Krueger 1999, p. 506)
	\begin{figure}
	\includegraphics[scale=0.6]{./lecture_includes/krueger1999_table4.pdf}
	\end{figure}

	\begin{itemize}
	\item Interpreting Krueger's``transition matrix'' (above) 
		\begin{itemize}
		\item If students remained in their same class type over time, all the off-diagonal elements would be zero
		\item Interpretation: Of the 1,482 first graders assigned to small classrooms, 1,435 remained in small classes; 23 and 24 switched into regular and regular with aide classes in the second grade
		\end{itemize}
	\item If students with stronger expected academic potential were more likely to move into the small classes, then these transitions would bias a simple comparison of outcomes across class types.
	\end{itemize}
\end{frame}

\begin{frame}[plain]
	\begin{center}
	\textbf{Problem 2: Switch Classrooms after Random Assignment}
	\end{center}

	\begin{itemize}
	\item Subjects moved between treatment and control groups.  How to address this?
	\item A common solution to this problem is to use initial classroom assignment (i.e., small or regular classes) as an \emph{instrument} for actual assignment.  We will discuss instrumental variables later, so I will hold off on that now.
	\item Krueger reports regression results where instead of the student's actual status as the treatment variable, he regresses performance against their \emph{randomly assigned class size}.  This is called the ``reduced form'' model, and we learn more about this when we cover IV.
	\item In Kindergarten, OLS and reduced form are the same because students remained in their initial class for at least one year.
	\item From grade 1 onwards, OLS and reduced form results differ.
	\end{itemize}
\end{frame}

\begin{frame}[plain]
	\begin{center}
	\textbf{Problem 2: Switch Classrooms after Random Assignment}
	\end{center}
	
	\begin{figure}
	\includegraphics[scale=0.4]{./lecture_includes/krueger1999_table5c.pdf}
	\end{figure}
\end{frame}




\begin{frame}{Comments}

\begin{itemize}
\item Natural experiments are valuable, but they don't always have the same certainty the way an RCT does
\item We use natural experiments when people won't let us run the RCTs we want to run!
\item Findings from natural experiments often push others to run RCTs -- like at eBay
\end{itemize}

\end{frame}


\begin{frame}{Going forward}

\begin{itemize}

\item Now let's move into a set of tools that will help us in two of the areas we cover:  DAGs
\item Matching/regression and instrumental variables both depend critically on knowing something about the data generating process
\item We'll be learning one way to assist you
\end{itemize}

\end{frame}



\end{document}

\begin{frame}{Welcome!}

  \begin{itemize}
	\item I'm Scott Cunningham, professor of economics at Baylor University, author of \underline{Causal Inference: the Mixtape}, organizer of the Mixtape Sessions platform with Kyle Butts (UC-Boulder PhD student)
	\item I love economics, econometrics and particularly causal inference and run workshops on causal inference all over the world on causal inference
	\item Workshops can be helpful ways to plug into one's methodological training, and online workshops are very helpful because of the recordings, the coding together, and bunch of bells and whistles (e.g., github repositories)
	\item Causal inference is an old field but which has increasingly drawn people to it (Nobel Prize two years ago maybe helped) 
  \end{itemize}

\end{frame}




\begin{frame}{4-day Causal Inference Workshop}

  \begin{itemize}
    \item We workshop together for 4-days, 9am to 5pm CST with 15 min breaks on the hour and a 1-hour lunch break at noon CST
    \item I tend to emphasize intuition, mechanics, narrow calculations, meaning, assumptions, code including actually taking time to code, advocate for data visualization -- in other words the art and the science
    \item I'm me, and I teach how I teach, with passion, enthusiasm, deep joy, but I'm not an econometrician so sometimes I take the long way to get there when an econometrician would do it much faster
  \end{itemize}

\end{frame}



\begin{frame}{Github repo}

  \begin{itemize}
    \item We will communicate with one another regularly in the Discord channel and I will always be monitoring it
    \item Encourage you to talk to each other there, help one another, network with one another, coauthor with one another!
    \item I will be distributing things to you, like code and slides, via the github repo: \url{github.com/Mixtape-Sessions/Causal-Inference-1}
    \item Each lecture will be recorded and then uploaded to Vimeo as a password protected file that you'll have access to into perpetuity
    \item Kyle Butts and I are committed to over time making the Github Repository like an open public library where the only club goods are (a) recordings, (b) Discord and (c) live lectures
  \end{itemize}

\end{frame}

\begin{frame}{Workshop (Part 1) Topics}

  \begin{enumerate}
    \item Foundations and Graphs: Day 1
    \item Graphs and Unconfoundedness: Day 2
    \item Instrumental Variables: Day 3
    \item Regression Discontinuity Design: Day 4
  \end{enumerate}

\end{frame}





